{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3e606c96-02b1-44ce-931a-ac2192f1f5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "622343aa-257a-4649-be03-2c554390fd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Analyzing the vocabulary of Pride and Prejudice\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70b1e0f-2d3c-42ab-9733-185ed3e5f527",
   "metadata": {},
   "source": [
    "Adjusting log-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "50a64918-bb37-44f2-9a27-e461b2c56559",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.setLogLevel('OFF')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bafc19-600a-4014-9d31-7e2f0c280843",
   "metadata": {},
   "source": [
    "## Ingest the data: spark.read\n",
    "\n",
    "Main structures for storing data: RDD and data frame\n",
    " * RDD: \"bag that you give orders to\"\n",
    " * data frame: stricter thant RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b939299d-3e81-463f-897b-ddcf1c6586b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e2f95365-10b3-4cd6-81e9-e9e410b8209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"/sparkdata/1342-0.txt\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37ff79a-e795-480a-a903-328d5dbc437e",
   "metadata": {},
   "source": [
    "## Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c4cbf393-4476-46b8-b2d3-4bed2f7bc07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "book = spark.read.text(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e296e3ed-7fde-49e1-a03e-7552c8309bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "005ebc7a-31b5-4ee2-b1ea-29e684fc7bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "book.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0a9fe5d4-1bbe-484c-82e7-ba23bab6e903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('value', 'string')]\n"
     ]
    }
   ],
   "source": [
    "print(book.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "640c0c7a-ee9b-4b02-8122-3ac6a37f52d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+\n",
      "|                                             value|\n",
      "+--------------------------------------------------+\n",
      "|The Project Gutenberg EBook of Pride and Prejud...|\n",
      "|                                                  |\n",
      "|This eBook is for the use of anyone anywhere at...|\n",
      "|almost no restrictions whatsoever.  You may cop...|\n",
      "|re-use it under the terms of the Project Gutenb...|\n",
      "|    with this eBook or online at www.gutenberg.org|\n",
      "|                                                  |\n",
      "|                                                  |\n",
      "|                        Title: Pride and Prejudice|\n",
      "|                                                  |\n",
      "+--------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "book.show(n=10, truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c67de6c-8a6e-49b5-a1cc-38f3e3790179",
   "metadata": {},
   "source": [
    "# Simple column transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8ace4c14-5283-4ca2-aeff-039901fbab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c292a813-9494-4040-ae8f-2820f0ad35ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                line|\n",
      "+--------------------+\n",
      "|[The, Project, Gu...|\n",
      "|                  []|\n",
      "|[This, eBook, is,...|\n",
      "|[almost, no, rest...|\n",
      "|[re-use, it, unde...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines = book.select(split(book.value, \" \").alias(\"line\"))\n",
    "\n",
    "lines.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4980ca50-60fa-46f9-9f35-1b69b402d464",
   "metadata": {},
   "source": [
    "### select()\n",
    "\n",
    "select one or more columns from df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6784a72f-1308-4fff-a1f0-f11ce490b672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book.select(book.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ff01a72a-06fe-40bb-af2e-d95149ce9fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## different ways to select a column\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "book.select(book.value)\n",
    "book.select(book['value'])\n",
    "book.select(col('value'))\n",
    "book.select('value')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fec7dd-e34a-4e4b-bf57-741d3c6b5ed7",
   "metadata": {},
   "source": [
    "### Renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7ab57dfc-4c67-4e73-8034-9062f228678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lines = book.select(split(book.value, \" \").alias(\"line\"))\n",
    "\n",
    "lines = book.select(split(book.value, \" \"))\n",
    "lines = lines.withColumnRenamed(\"split(value, , -1)\", \"line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cbf78f62-d83c-410b-871d-dbed986d09a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = lines.withColumnRenamed(\"split(value,  , -1)\", \"line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "14dd3fdd-f4c6-458f-8db3-3bdbc35a3334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                line|\n",
      "+--------------------+\n",
      "|[The, Project, Gu...|\n",
      "|                  []|\n",
      "|[This, eBook, is,...|\n",
      "|[almost, no, rest...|\n",
      "|[re-use, it, unde...|\n",
      "|[with, this, eBoo...|\n",
      "|                  []|\n",
      "|                  []|\n",
      "|[Title:, Pride, a...|\n",
      "|                  []|\n",
      "|[Author:, Jane, A...|\n",
      "|                  []|\n",
      "|[Posting, Date:, ...|\n",
      "|[Release, Date:, ...|\n",
      "|[Last, Updated:, ...|\n",
      "|                  []|\n",
      "|[Language:, English]|\n",
      "|                  []|\n",
      "|[Character, set, ...|\n",
      "|                  []|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83a8c5e-b374-4ce3-b887-38cbbeb9fb01",
   "metadata": {},
   "source": [
    "### Explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7b9a7fb5-f5fc-436a-9d03-3869d306e515",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dea22b66-fe20-4234-8314-3968e863c438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      word|\n",
      "+----------+\n",
      "|       The|\n",
      "|   Project|\n",
      "| Gutenberg|\n",
      "|     EBook|\n",
      "|        of|\n",
      "|     Pride|\n",
      "|       and|\n",
      "|Prejudice,|\n",
      "|        by|\n",
      "|      Jane|\n",
      "|    Austen|\n",
      "|          |\n",
      "|      This|\n",
      "|     eBook|\n",
      "|        is|\n",
      "+----------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = lines.select(explode(col=('line')).alias(\"word\"))\n",
    "\n",
    "words.show(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b3901e-cc3f-495a-923c-fecdc11ebc16",
   "metadata": {},
   "source": [
    "### Lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "26d33d76-284e-4dd2-9427-cee3acd27cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|word_lower|\n",
      "+----------+\n",
      "|       the|\n",
      "|   project|\n",
      "| gutenberg|\n",
      "|     ebook|\n",
      "|        of|\n",
      "|     pride|\n",
      "|       and|\n",
      "|prejudice,|\n",
      "|        by|\n",
      "|      jane|\n",
      "|    austen|\n",
      "|          |\n",
      "|      this|\n",
      "|     ebook|\n",
      "|        is|\n",
      "+----------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lower\n",
    "\n",
    "words_lower = words.select(lower(col('word')).alias(\"word_lower\"))\n",
    "\n",
    "words_lower.show(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e391f71-d8cf-42e7-b6c1-588f41109421",
   "metadata": {},
   "source": [
    "### RegExp functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "58ae603d-1f5a-47ce-9f03-9012658a54b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     word|\n",
      "+---------+\n",
      "|      the|\n",
      "|  project|\n",
      "|gutenberg|\n",
      "|    ebook|\n",
      "|       of|\n",
      "|    pride|\n",
      "|      and|\n",
      "|prejudice|\n",
      "|       by|\n",
      "|     jane|\n",
      "|   austen|\n",
      "|         |\n",
      "|     this|\n",
      "|    ebook|\n",
      "|       is|\n",
      "+---------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "words_clean = words_lower.select(\n",
    "    regexp_extract(col(\"word_lower\"), \"[a-z]+\",0).alias(\"word\")\n",
    ")\n",
    "\n",
    "words_clean.show(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e31a1d1-bf16-4e14-bfcd-b46f37d8e830",
   "metadata": {},
   "source": [
    "###  Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2f0debe9-d789-4998-bc21-cffeb003e023",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     word|\n",
      "+---------+\n",
      "|      the|\n",
      "|  project|\n",
      "|gutenberg|\n",
      "|    ebook|\n",
      "|       of|\n",
      "|    pride|\n",
      "|      and|\n",
      "|prejudice|\n",
      "|       by|\n",
      "|     jane|\n",
      "|   austen|\n",
      "|     this|\n",
      "|    ebook|\n",
      "|       is|\n",
      "|      for|\n",
      "|      the|\n",
      "|      use|\n",
      "|       of|\n",
      "|   anyone|\n",
      "| anywhere|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_null = words_clean.filter(col(\"word\")!='')\n",
    "\n",
    "words_null.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bde4ef-a9c1-442c-91b8-0b1424775beb",
   "metadata": {},
   "source": [
    "### Writing file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "dee9d9b4-e681-4f01-8e25-bfe883f993d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_null.write.csv('word_count.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d32d821-1cdc-40cb-b475-029e49ce2a58",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "019e27b5-5540-4e0a-871f-176c69f7f792",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3566ca-33b3-4bc6-8cb5-196cb5c3ed9c",
   "metadata": {},
   "source": [
    "#### 2.2 \n",
    "Given the following data frame, programmatically count the number of columns that\n",
    "aren’t strings (answer = only one column isn’t a string).\n",
    "createDataFrame() allows you to create a data frame from a variety of sources,\n",
    "such as a pandas data frame or (in this case) a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46798c2c-575d-460e-be86-f81d83633185",
   "metadata": {},
   "outputs": [],
   "source": [
    "exo2_2_df = spark.createDataFrame(\n",
    "[[\"test\", \"more test\", 10_000_000_000]], [\"one\", \"two\", \"three\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9428f9ab-07c6-4479-bec7-52b5e1167adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exo2_2_df[[i[0] for i in exo2_2_df.dtypes if i[1] != 'string']].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eba58cb7-929f-4422-9235-6331f4b83236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[one: string, two: string]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exo2_2_df.select(col('one'),col('two'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073eccdb-a48a-4b23-a65b-f98d5343bc6a",
   "metadata": {},
   "source": [
    "#### 2.3\n",
    "Rewrite the following code snippet, removing the withColumnRenamed method. Which\n",
    "version is clearer and easier to read?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "889e5c69-9d9f-418e-bac9-f707d4ee811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7567e37-2bff-4014-9e82-fd840fbea7cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, length\n",
    "# The `length` function returns the number of characters in a string column.\n",
    "exo2_3_df = (\n",
    "spark.read.text(\"./data/gutenberg_books/1342-0.txt\")\n",
    ".select(length(col(\"value\")))\n",
    ".withColumnRenamed(\"length(value)\", \"number_of_char\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "99b51185-bfba-4ea3-8948-32c53aad5b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "exo2_3_df = (\n",
    "spark.read.text(csv_path)\n",
    ".select(length(col(\"value\")).alias(\"number_of_char\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd5994a6-1650-4431-81bd-f0b6802d9f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|number_of_char|\n",
      "+--------------+\n",
      "|            66|\n",
      "|             0|\n",
      "|            64|\n",
      "|            68|\n",
      "|            67|\n",
      "|            46|\n",
      "|             0|\n",
      "|             0|\n",
      "|            26|\n",
      "|             0|\n",
      "|            19|\n",
      "|             0|\n",
      "|            43|\n",
      "|            24|\n",
      "|            28|\n",
      "|             0|\n",
      "|            17|\n",
      "|             0|\n",
      "|            29|\n",
      "|             0|\n",
      "+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exo2_3_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de29b020-ee80-4561-ae23-91c09b57a9a8",
   "metadata": {},
   "source": [
    "#### 2.4 \n",
    "Assume a data frame exo2_4_df. The following code block gives an error. What is the\n",
    "problem, and how can you solve it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1bc05f14-9103-4a03-8e87-8fc0f1bb6ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: string (nullable = true)\n",
      " |-- value1: long (nullable = true)\n",
      " |-- value2: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, greatest\n",
    "exo2_4_df = spark.createDataFrame(\n",
    "[[\"key\", 10_000, 20_000]], [\"key\", \"value1\", \"value2\"]\n",
    ")\n",
    "exo2_4_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee9d10d8-29f1-4460-a65f-43bfd1d513d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `key` cannot be resolved. Did you mean one of the following? [`maximum_value`].;\n",
      "'Project ['key, 'max_value]\n",
      "+- Project [greatest(value1#77L, value2#78L) AS maximum_value#82L]\n",
      "   +- LogicalRDD [key#76, value1#77L, value2#78L], false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# `greatest` will return the greatest value of the list of column names,\n",
    "# skipping null value\n",
    "# The following statement will return an error\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "try:\n",
    "    exo2_4_mod = exo2_4_df.select(\n",
    "    greatest(col(\"value1\"), col(\"value2\")).alias(\"maximum_value\")\n",
    "    ).select(\"key\", \"max_value\")\n",
    "except AnalysisException as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68cbcda-7906-43f5-9495-ac2cbdeef228",
   "metadata": {},
   "source": [
    "We are defining a dataframe which has the greatest as a single column, so there is no 'key' column to select from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f880578-fcc9-4ca2-a710-98c4616b5232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|maximum_value|\n",
      "+-------------+\n",
      "|        20000|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exo2_4_df.select(\n",
    "    greatest(col(\"value1\"), col(\"value2\")).alias(\"maximum_value\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c984e4f3-2545-4b04-8437-630861b2df57",
   "metadata": {},
   "source": [
    "We need to select the rest of the columns with the greatest function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "15110f62-f3d6-4144-9406-5b7618f9db20",
   "metadata": {},
   "outputs": [],
   "source": [
    "exo2_4_mod = exo2_4_df.select(col('key'),\n",
    "    greatest(col(\"value1\"), col(\"value2\")).alias(\"maximum_value\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "36ef3295-2b9d-40e0-b68f-753ae28207e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+\n",
      "|key|maximum_value|\n",
      "+---+-------------+\n",
      "|key|        20000|\n",
      "+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exo2_4_mod.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f9271f-4ea7-4529-a83c-aaf2642eb110",
   "metadata": {},
   "source": [
    "####  2.5\n",
    "Let’s take our words_nonull data frame, available in the next listing. You can use the\n",
    "code from the repository (code/Ch02/end_of_chapter.py) in your REPL to get the\n",
    "data frame loaded.\n",
    "\n",
    "a) Remove all of the occurrences of the word is.\n",
    "\n",
    "b) (Challenge) Using the length function, keep only the words with more than three\n",
    "characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "439671ef-4f03-481f-9a58-f6c5c18a7b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import filter, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "044f2d22-3d35-46cb-b62f-8d7225974589",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_no_is = words_null.filter(col('word')!='is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d1c9ca1b-7777-481a-83f6-29bcbc751362",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_3 = words_null.filter(length(col('word'))<=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9964d7fe-b8a2-48a6-a70f-52687deaa49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|word|\n",
      "+----+\n",
      "| the|\n",
      "|  of|\n",
      "| and|\n",
      "|  by|\n",
      "|  is|\n",
      "| for|\n",
      "| the|\n",
      "| use|\n",
      "|  of|\n",
      "|  at|\n",
      "|  no|\n",
      "| and|\n",
      "|  no|\n",
      "| you|\n",
      "| may|\n",
      "|  it|\n",
      "|  it|\n",
      "|  or|\n",
      "|  re|\n",
      "|  it|\n",
      "+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af5cd49-5658-4be2-abbb-9974df722b6a",
   "metadata": {},
   "source": [
    "#### 2.6\n",
    "The where clause takes a Boolean expression over one or many columns to filter the\n",
    "data frame. Beyond the usual Boolean operators (>, <, ==, <=, >=, !=), PySpark provides\n",
    "other functions that return Boolean columns in the pyspark.sql.functions\n",
    "module.\n",
    "A good example is the isin() method (applied on a Column object, like\n",
    "col(…).isin(…)), which takes a list of values as a parameter, and will return only the\n",
    "records where the value in the column equals a member of the list.\n",
    "Let’s say you want to remove the words is, not, the and if from your list of words,\n",
    "using a single where() method on the words_nonull data frame. Write the code to\n",
    "do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "117e8e16-15b7-4591-ac69-0604fe33e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words = words_null.where(~col('word').isin('is','not','the','if'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2b3afc43-a982-459b-a5c4-157458c15918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     word|\n",
      "+---------+\n",
      "|  project|\n",
      "|gutenberg|\n",
      "|    ebook|\n",
      "|       of|\n",
      "|    pride|\n",
      "|      and|\n",
      "|prejudice|\n",
      "|       by|\n",
      "|     jane|\n",
      "|   austen|\n",
      "|     this|\n",
      "|    ebook|\n",
      "|      for|\n",
      "|      use|\n",
      "|       of|\n",
      "|   anyone|\n",
      "| anywhere|\n",
      "|       at|\n",
      "|       no|\n",
      "|     cost|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_words.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4b58cf-1c63-4e86-895d-2919e4fa6aaa",
   "metadata": {},
   "source": [
    "#### 2.7\n",
    "One of your friends comes to you with the following code. They have no idea why it\n",
    "doesn’t work. Can you diagnose the problem in the try block, explain why it is an\n",
    "error, and provide a fix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0b1dd6b9-11ec-447d-a6f2-abea5cb82db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'select'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m     book \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mtext(csv_path)\n\u001b[1;32m      4\u001b[0m     book \u001b[38;5;241m=\u001b[39m book\u001b[38;5;241m.\u001b[39mprintSchema()\n\u001b[0;32m----> 5\u001b[0m     lines \u001b[38;5;241m=\u001b[39m \u001b[43mbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m(split(book\u001b[38;5;241m.\u001b[39mvalue, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mline\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      6\u001b[0m     words \u001b[38;5;241m=\u001b[39m lines\u001b[38;5;241m.\u001b[39mselect(explode(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mline\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m AnalysisException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'select'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, split\n",
    "try:\n",
    "    book = spark.read.text(csv_path)\n",
    "    book = book.printSchema()\n",
    "    lines = book.select(split(book.value, \" \").alias(\"line\"))\n",
    "    words = lines.select(explode(col(\"line\")).alias(\"word\"))\n",
    "except AnalysisException as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a03467-b075-4800-b009-ad477be01095",
   "metadata": {},
   "source": [
    "The problem comes from assigning book as book.printSchema(), since printing returns nothing, book becomes None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c5a8f612-0148-487b-983d-7ad9e202288b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "book = spark.read.text(csv_path)\n",
    "book.printSchema()\n",
    "lines = book.select(split(book.value, \" \").alias(\"line\"))\n",
    "words = lines.select(explode(col(\"line\")).alias(\"word\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "21b41642-8b89-42de-9e09-8972227c0b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      word|\n",
      "+----------+\n",
      "|       The|\n",
      "|   Project|\n",
      "| Gutenberg|\n",
      "|     EBook|\n",
      "|        of|\n",
      "|     Pride|\n",
      "|       and|\n",
      "|Prejudice,|\n",
      "|        by|\n",
      "|      Jane|\n",
      "|    Austen|\n",
      "|          |\n",
      "|      This|\n",
      "|     eBook|\n",
      "|        is|\n",
      "|       for|\n",
      "|       the|\n",
      "|       use|\n",
      "|        of|\n",
      "|    anyone|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bf24fb-b677-49d8-98d0-f5667f09ec29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
