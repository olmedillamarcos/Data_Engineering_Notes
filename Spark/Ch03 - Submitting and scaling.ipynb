{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3f74725-7cab-448a-849b-608e163a34e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f04e0f67-4edd-41d2-ab37-6a498fa5d96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"/sparkdata/1342-0.txt\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da9e7e80-ff86-404f-be4c-3d9f6c98487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Analyzing the vocabulary of Pride and Prejudice\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdd1b35f-3887-42c1-b841-d6b6747b1a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_null = spark.read.csv('word_count.csv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06de528e-8c41-456e-ae23-86e9e226b90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_null = word_null.withColumnRenamed('_c0','word')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864ec079-10d2-4fcc-9e7f-07516734a4e4",
   "metadata": {},
   "source": [
    "### Grouping records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "368d3316-dfec-4564-8a89-33c25a75bf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = word_null.groupby(col('word'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31e0aa02-11f5-41aa-a01b-38e26f82f666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupedData[grouping expressions: [word], value: [word: string], type: GroupBy]\n"
     ]
    }
   ],
   "source": [
    "print(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30a0c5a3-e97b-4c16-a50e-1faae00c6a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = groups.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfccde4e-74cd-4d8e-a40a-5adf4c2b6be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[word: string, count: bigint]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3cee0acd-7555-4a74-a7eb-afbe746e606c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|  word|count|\n",
      "+------+-----+\n",
      "|online|    4|\n",
      "|  some|  209|\n",
      "| still|   72|\n",
      "|   few|   72|\n",
      "|  hope|  122|\n",
      "+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ffecd4-a9b9-4a22-b12e-c937b23e2f59",
   "metadata": {},
   "source": [
    "### Ordering results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dcb2248f-a71d-435d-b25a-1ac8934b7d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "| the| 4496|\n",
      "|  to| 4235|\n",
      "|  of| 3719|\n",
      "| and| 3602|\n",
      "| her| 2223|\n",
      "+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.orderBy('count',ascending = False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1718e6b-f5ef-4fe2-8408-edc6f40c1f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "| the| 4496|\n",
      "|  to| 4235|\n",
      "|  of| 3719|\n",
      "| and| 3602|\n",
      "| her| 2223|\n",
      "+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Can also call the col function\n",
    "results.orderBy(col(\"count\").desc()).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4425f88c-5777-4ea2-afa2-d94471162952",
   "metadata": {},
   "source": [
    "### Writing data from a data frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a17d414-b74e-4212-ac50-efbe695fc206",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.write.csv('simple_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35818083-b9db-4a43-8d89-cc56a9524507",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## changing number of partitions with dataframe.coalesce()\n",
    "results.coalesce(3).write.csv('simple_count_partition.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fc3910-37ee-42a0-82e0-d40c94c06dc0",
   "metadata": {},
   "source": [
    "#### all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f72f34-dc4f-4497-9214-687bc3f593bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col,\n",
    "    explode,\n",
    "    lower,\n",
    "    regexp_extract,\n",
    "    sp\n",
    "lit,\n",
    ")\n",
    "spark = SparkSession.builder.appName(\n",
    "    \"Analyzing the vocabulary of Pride and Prejudice.\"\n",
    ").getOrCreate()\n",
    "\n",
    "book = spark.read.text(\"./data/gutenberg_books/1342-0.txt\")\n",
    "\n",
    "lines = book.select(split(book.value, \" \").alias(\"line\"))\n",
    "\n",
    "words = lines.select(explode(col(\"line\")).alias(\"word\"))\n",
    "\n",
    "words_lower = words.select(lower(col(\"word\")).alias(\"word\"))\n",
    "\n",
    "words_clean = words_lower.select(\n",
    "    regexp_extract(col(\"word\"), \"[a-z']*\", 0).alias(\"word\")\n",
    ")\n",
    "\n",
    "words_nonull = words_clean.where(col(\"word\") != \"\")\n",
    "\n",
    "results = words_nonull.groupby(col(\"word\")).count()\n",
    "\n",
    "results.orderBy(\"count\", ascending=False).show(10)\n",
    "\n",
    "results.coalesce(1).write.csv(\"./simple_count_single_partition.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94691352-2ef1-4d5f-a4ff-10054a3226a2",
   "metadata": {},
   "source": [
    "### Simplifyign PySpark import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e66ce-8ca7-4040-b13c-4f4538567eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Since we usually use a lot of functions from pyspark.sql, instead of doing this:\n",
    "from pyspark.sql.functions import col, explode, lower\n",
    "\n",
    "## it is useful to import the whole module:\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e887ce-a98b-46f8-9008-78776ff203ed",
   "metadata": {},
   "source": [
    "### Method Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159b8347-d199-4335-b158-673281d5218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before\n",
    "book = spark.read.text(\"./data/gutenberg_books/1342-0.txt\")\n",
    "\n",
    "lines = book.select(split(book.value, \" \").alias(\"line\"))\n",
    "\n",
    "words = lines.select(explode(col(\"line\")).alias(\"word\"))\n",
    "\n",
    "words_lower = words.select(lower(col(\"word\")).alias(\"word\"))\n",
    "\n",
    "words_clean = words_lower.select(\n",
    "    regexp_extract(col(\"word\"), \"[a-z']*\", 0).alias(\"word\")\n",
    ")\n",
    "\n",
    "words_nonull = words_clean.where(col(\"word\") != \"\")\n",
    "\n",
    "results = words_nonull.groupby(\"word\").count()\n",
    "\n",
    "# After\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "results = (\n",
    "    spark.read.text(csv_path)\n",
    "    .select(F.split(F.col(\"value\"), \" \").alias(\"line\"))\n",
    "    .select(F.explode(F.col(\"line\")).alias(\"word\"))\n",
    "    .select(F.lower(F.col(\"word\")).alias(\"word\"))\n",
    "    .select(F.regexp_extract(F.col(\"word\"), \"[a-z']*\", 0).alias(\"word\"))\n",
    "    .where(F.col(\"word\") != \"\")\n",
    "    .groupby(\"word\")\n",
    "    .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548d89e4-af9f-4899-8c91-b4bd0670edc8",
   "metadata": {},
   "source": [
    "### Reading Multiple Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e64321-3dbb-4172-bc31-b1acf5930503",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.text('./data/gutenberg_books/*.txt') ## note the glob pattern at *"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
