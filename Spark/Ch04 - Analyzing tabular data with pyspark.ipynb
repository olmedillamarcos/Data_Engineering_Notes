{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9dcc8b0-b49e-4476-a64a-eeba33625cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb8632dd-4a99-43a3-936d-b4a20aa06661",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb52c7-a573-43ab-80a1-b8de2839f0eb",
   "metadata": {},
   "source": [
    "tabular data - data represented in a two-dimensional table. Cells with each containing a single value, organized into rows and columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764ee1e5-c9d2-48fc-b1a2-50a19cfb1838",
   "metadata": {},
   "source": [
    "#### Creating a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbe85fb-5cbf-438f-a253-1d5f6eb48dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### first parameter: data - can be list of lists, pandas df, or RDD (resilient distributed dataset)\n",
    "### second parametr: schema -\n",
    "spark.createDataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fc50ad-490b-440d-afb0-d4945aa4d0d9",
   "metadata": {},
   "source": [
    "### PySpark for analyzing and processing tabular data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef32ca8-d937-4315-b886-5a46cc51d9ef",
   "metadata": {},
   "source": [
    "Note: when using toPandas(), remember that you lose the advantages of working with multiple machines, as the data will accumulate on the driver &rarr; use for an aggregated or manageable (rows X columns <= 100000) data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04d017a8-8a09-47cf-838d-6c21677a982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcast_sample = \"/sparkdata/DataAnalysisWithPythonAndPySpark-Data/broadcast_logs/BroadcastLogs_2018_Q3_M8_sample.CSV\"\n",
    "call_signs = \"/sparkdata/DataAnalysisWithPythonAndPySpark-Data/broadcast_logs/Call_Signs\"\n",
    "data_dict = \"/sparkdata/DataAnalysisWithPythonAndPySpark-Data/broadcast_logs/data dictionary.doc\"\n",
    "ref_tables = \"/sparkdata/DataAnalysisWithPythonAndPySpark-Data/broadcast_logs/ReferenceTables\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47228720-c969-499c-a803-1df4311ab1c0",
   "metadata": {},
   "source": [
    "#### Reading and acessing delimited data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "232e8d7e-ed8c-481a-a4a4-30099e328c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = spark.read.csv(\n",
    "    broadcast_sample,\n",
    "    sep=\"|\",\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    "    timestampFormat=\"yyyy-MM-dd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347b709f-052d-417c-a274-cc6f90a927ba",
   "metadata": {},
   "source": [
    "PySpark can infer the schema of a CSV file by setting the inferSchema optional\n",
    "parameter to True. PySpark accomplishes this by reading the data twice: once\n",
    "for setting the appropriate types for each column and once to ingest the data in\n",
    "the inferred format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71039081-4358-43ca-b6cc-7f7f3a9c480f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- BroadcastLogID: integer (nullable = true)\n",
      " |-- LogServiceID: integer (nullable = true)\n",
      " |-- LogDate: date (nullable = true)\n",
      " |-- SequenceNO: integer (nullable = true)\n",
      " |-- AudienceTargetAgeID: integer (nullable = true)\n",
      " |-- AudienceTargetEthnicID: integer (nullable = true)\n",
      " |-- CategoryID: integer (nullable = true)\n",
      " |-- ClosedCaptionID: integer (nullable = true)\n",
      " |-- CountryOfOriginID: integer (nullable = true)\n",
      " |-- DubDramaCreditID: integer (nullable = true)\n",
      " |-- EthnicProgramID: integer (nullable = true)\n",
      " |-- ProductionSourceID: integer (nullable = true)\n",
      " |-- ProgramClassID: integer (nullable = true)\n",
      " |-- FilmClassificationID: integer (nullable = true)\n",
      " |-- ExhibitionID: integer (nullable = true)\n",
      " |-- Duration: string (nullable = true)\n",
      " |-- EndTime: string (nullable = true)\n",
      " |-- LogEntryDate: date (nullable = true)\n",
      " |-- ProductionNO: string (nullable = true)\n",
      " |-- ProgramTitle: string (nullable = true)\n",
      " |-- StartTime: string (nullable = true)\n",
      " |-- Subtitle: string (nullable = true)\n",
      " |-- NetworkAffiliationID: integer (nullable = true)\n",
      " |-- SpecialAttentionID: integer (nullable = true)\n",
      " |-- BroadcastOriginPointID: integer (nullable = true)\n",
      " |-- CompositionID: integer (nullable = true)\n",
      " |-- Producer1: string (nullable = true)\n",
      " |-- Producer2: string (nullable = true)\n",
      " |-- Language1: integer (nullable = true)\n",
      " |-- Language2: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8d67c5-4dad-453b-bcc2-21ae3e0a17e3",
   "metadata": {},
   "source": [
    "### The basics of data manipulation: Selecting, dropping, renaming, ordering, diagnosing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e50025-b899-44c0-9189-ddb475ef5262",
   "metadata": {},
   "source": [
    "#### <b>select() method</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff015690-d522-47a8-80fa-4dc3fee6be84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+----------+\n",
      "|BroadcastLogID|LogServiceID|LogDate   |\n",
      "+--------------+------------+----------+\n",
      "|1196192316    |3157        |2018-08-01|\n",
      "|1196192317    |3157        |2018-08-01|\n",
      "|1196192318    |3157        |2018-08-01|\n",
      "|1196192319    |3157        |2018-08-01|\n",
      "|1196192320    |3157        |2018-08-01|\n",
      "+--------------+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs.select(\"BroadcastLogID\", \"LogServiceID\", \"LogDate\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1170729-2f04-4645-acc4-3e65f087a2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the string to column conversion\n",
    "logs.select(\"BroadCastLogID\", \"LogServiceID\", \"LogDate\")\n",
    "\n",
    "logs.select(*[\"BroadCastLogID\", \"LogServiceID\", \"LogDate\"])\n",
    "\n",
    "# Passing the column object explicitly\n",
    "logs.select(\n",
    "    F.col(\"BroadCastLogID\"), F.col(\"LogServiceID\"), F.col(\"LogDate\")\n",
    ")\n",
    "\n",
    "logs.select(\n",
    "    *[F.col(\"BroadCastLogID\"), F.col(\"LogServiceID\"), F.col(\"LogDate\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb44d0d9-d5cc-4854-a32a-2ff7c9db8191",
   "metadata": {},
   "source": [
    "Note: when using Databricks, simply call display(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b043e3e-9dbf-4343-a9fd-3359b63fe37c",
   "metadata": {},
   "source": [
    "#### <b>Deleting columns</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69c8201e-9d98-4ccc-9830-a4e2205cf7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = logs.drop(\"BroadcastLogID\",\"SequenceNO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "218902ae-85fa-4abd-9000-a11c5303b51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(\"BroadcastLogID\" in logs.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d46fa368-b397-4984-ae1f-2e925005796e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(\"SequenceNO\" in logs.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d049c227-61cd-4f2f-a301-6746e4dcfc86",
   "metadata": {},
   "source": [
    "Unlike select(), dropping a nonexistent column is a no-op. PySpark will ignore columns it does not find."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aa713c-9e12-4318-9bef-77fb0142e347",
   "metadata": {},
   "source": [
    "#### <b>New columns with _withColumn()_</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "604ad5f0-c0ab-43f4-a98b-ab4251610915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08c5b43e-04f0-409b-9ed5-e228d71486c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|        Duration|\n",
      "+----------------+\n",
      "|02:00:00.0000000|\n",
      "|00:00:30.0000000|\n",
      "|00:00:15.0000000|\n",
      "|00:00:15.0000000|\n",
      "|00:00:15.0000000|\n",
      "+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs.select(F.col(\"Duration\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98cbaf86-8fbb-4a13-a34e-b92faee86844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Duration', 'string')]\n"
     ]
    }
   ],
   "source": [
    "print(logs.select(F.col(\"Duration\")).dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44334342-e4e1-4b2a-a080-91d3d4c4ec13",
   "metadata": {},
   "source": [
    "We see that the column has string types, formatted as HH:MM:SS.mmmmmmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21b3e9b8-a490-443b-8750-0a273100fdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+-------+-----------+\n",
      "|        Duration|dur_hours|dur_min|dur_seconds|\n",
      "+----------------+---------+-------+-----------+\n",
      "|00:04:52.0000000|        0|      4|         52|\n",
      "|00:10:06.0000000|        0|     10|          6|\n",
      "|00:26:41.0000000|        0|     26|         41|\n",
      "|00:05:29.0000000|        0|      5|         29|\n",
      "|00:08:18.0000000|        0|      8|         18|\n",
      "+----------------+---------+-------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ignoring milliseconds\n",
    "logs.select(\n",
    "    F.col(\"Duration\"),\n",
    "    F.col(\"Duration\").substr(1,2).cast(\"int\").alias(\"dur_hours\"),\n",
    "    F.col(\"Duration\").substr(4,2).cast(\"int\").alias(\"dur_min\"),\n",
    "    F.col(\"Duration\").substr(7,2).cast(\"int\").alias(\"dur_seconds\")\n",
    ").distinct().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1dd37bfe-272e-4e05-ae0a-ca678ad3b43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+\n",
      "|        Duration|Duration_seconds|\n",
      "+----------------+----------------+\n",
      "|01:59:30.0000000|            7170|\n",
      "|00:31:00.0000000|            1860|\n",
      "|00:28:08.0000000|            1688|\n",
      "|00:10:30.0000000|             630|\n",
      "|00:32:00.0000000|            1920|\n",
      "+----------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## summarizing the duration to seconds\n",
    "logs.select(\n",
    "    F.col(\"Duration\"),\n",
    "    (\n",
    "        F.col(\"Duration\").substr(1,2).cast(\"int\")*60*60\n",
    "        + F.col(\"Duration\").substr(4,2).cast(\"int\")*60\n",
    "        + F.col(\"Duration\").substr(7,2).cast(\"int\")\n",
    "    ).alias(\"Duration_seconds\")\n",
    ").distinct().show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b72bb4-66ab-4dfe-82cd-fe498d4c06c3",
   "metadata": {},
   "source": [
    "#### What if we only add a column to the end of our df?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71e01edf-687e-475f-bcb1-ac840bc36fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = logs.withColumn(\n",
    "    \"Duration_seconds\",\n",
    "    (\n",
    "        F.col(\"Duration\").substr(1,2).cast(\"int\")*60*60\n",
    "        + F.col(\"Duration\").substr(4,2).cast(\"int\")*60\n",
    "        + F.col(\"Duration\").substr(7,2).cast(\"int\")\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6793d020-2072-4ddf-9114-2a32aeef2c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LogServiceID: integer (nullable = true)\n",
      " |-- LogDate: date (nullable = true)\n",
      " |-- AudienceTargetAgeID: integer (nullable = true)\n",
      " |-- AudienceTargetEthnicID: integer (nullable = true)\n",
      " |-- CategoryID: integer (nullable = true)\n",
      " |-- ClosedCaptionID: integer (nullable = true)\n",
      " |-- CountryOfOriginID: integer (nullable = true)\n",
      " |-- DubDramaCreditID: integer (nullable = true)\n",
      " |-- EthnicProgramID: integer (nullable = true)\n",
      " |-- ProductionSourceID: integer (nullable = true)\n",
      " |-- ProgramClassID: integer (nullable = true)\n",
      " |-- FilmClassificationID: integer (nullable = true)\n",
      " |-- ExhibitionID: integer (nullable = true)\n",
      " |-- Duration: string (nullable = true)\n",
      " |-- EndTime: string (nullable = true)\n",
      " |-- LogEntryDate: date (nullable = true)\n",
      " |-- ProductionNO: string (nullable = true)\n",
      " |-- ProgramTitle: string (nullable = true)\n",
      " |-- StartTime: string (nullable = true)\n",
      " |-- Subtitle: string (nullable = true)\n",
      " |-- NetworkAffiliationID: integer (nullable = true)\n",
      " |-- SpecialAttentionID: integer (nullable = true)\n",
      " |-- BroadcastOriginPointID: integer (nullable = true)\n",
      " |-- CompositionID: integer (nullable = true)\n",
      " |-- Producer1: string (nullable = true)\n",
      " |-- Producer2: string (nullable = true)\n",
      " |-- Language1: integer (nullable = true)\n",
      " |-- Language2: integer (nullable = true)\n",
      " |-- Duration_seconds: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865dfb25-c662-4e7e-b04b-1f9b4c5541cf",
   "metadata": {},
   "source": [
    "Using withColumn() and giving a name that already exists in the dataframe will make PySpark overwrite the existing column.\n",
    "\n",
    "We can create columns both with select() and withColumn(). select() will be useful when we want to work with a few columns, and withColumn() will be useful when we want to add some columns without changing the reset of the data set.\n",
    " * Creating many (100+) new columns with withColumn() will slow Spark. For these cases, use select()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a943d57-dffe-428e-803d-0044e405d6b9",
   "metadata": {},
   "source": [
    "#### <b>Renaming and reordering columns</b>\n",
    "can be done with select() and alias(), but also with withColumnRenamed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1cf7f47-6b18-43f1-ac4d-ebc1ea3a3639",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = logs.withColumnRenamed(\"Duration_seconds\",\"duration_seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7aca2b68-ea79-41a6-8522-21c89bb1616b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LogServiceID: integer (nullable = true)\n",
      " |-- LogDate: date (nullable = true)\n",
      " |-- AudienceTargetAgeID: integer (nullable = true)\n",
      " |-- AudienceTargetEthnicID: integer (nullable = true)\n",
      " |-- CategoryID: integer (nullable = true)\n",
      " |-- ClosedCaptionID: integer (nullable = true)\n",
      " |-- CountryOfOriginID: integer (nullable = true)\n",
      " |-- DubDramaCreditID: integer (nullable = true)\n",
      " |-- EthnicProgramID: integer (nullable = true)\n",
      " |-- ProductionSourceID: integer (nullable = true)\n",
      " |-- ProgramClassID: integer (nullable = true)\n",
      " |-- FilmClassificationID: integer (nullable = true)\n",
      " |-- ExhibitionID: integer (nullable = true)\n",
      " |-- Duration: string (nullable = true)\n",
      " |-- EndTime: string (nullable = true)\n",
      " |-- LogEntryDate: date (nullable = true)\n",
      " |-- ProductionNO: string (nullable = true)\n",
      " |-- ProgramTitle: string (nullable = true)\n",
      " |-- StartTime: string (nullable = true)\n",
      " |-- Subtitle: string (nullable = true)\n",
      " |-- NetworkAffiliationID: integer (nullable = true)\n",
      " |-- SpecialAttentionID: integer (nullable = true)\n",
      " |-- BroadcastOriginPointID: integer (nullable = true)\n",
      " |-- CompositionID: integer (nullable = true)\n",
      " |-- Producer1: string (nullable = true)\n",
      " |-- Producer2: string (nullable = true)\n",
      " |-- Language1: integer (nullable = true)\n",
      " |-- Language2: integer (nullable = true)\n",
      " |-- duration_seconds: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12784d92-75e7-4e97-9283-df01656525e2",
   "metadata": {},
   "source": [
    "applying to all columns: toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bcce97f8-3803-4145-af82-1bbac5e47974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- logserviceid: integer (nullable = true)\n",
      " |-- logdate: date (nullable = true)\n",
      " |-- audiencetargetageid: integer (nullable = true)\n",
      " |-- audiencetargetethnicid: integer (nullable = true)\n",
      " |-- categoryid: integer (nullable = true)\n",
      " |-- closedcaptionid: integer (nullable = true)\n",
      " |-- countryoforiginid: integer (nullable = true)\n",
      " |-- dubdramacreditid: integer (nullable = true)\n",
      " |-- ethnicprogramid: integer (nullable = true)\n",
      " |-- productionsourceid: integer (nullable = true)\n",
      " |-- programclassid: integer (nullable = true)\n",
      " |-- filmclassificationid: integer (nullable = true)\n",
      " |-- exhibitionid: integer (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- endtime: string (nullable = true)\n",
      " |-- logentrydate: date (nullable = true)\n",
      " |-- productionno: string (nullable = true)\n",
      " |-- programtitle: string (nullable = true)\n",
      " |-- starttime: string (nullable = true)\n",
      " |-- subtitle: string (nullable = true)\n",
      " |-- networkaffiliationid: integer (nullable = true)\n",
      " |-- specialattentionid: integer (nullable = true)\n",
      " |-- broadcastoriginpointid: integer (nullable = true)\n",
      " |-- compositionid: integer (nullable = true)\n",
      " |-- producer1: string (nullable = true)\n",
      " |-- producer2: string (nullable = true)\n",
      " |-- language1: integer (nullable = true)\n",
      " |-- language2: integer (nullable = true)\n",
      " |-- duration_seconds: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs.toDF(*[x.lower() for x in logs.columns]).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85f2e76-ca78-47b9-bdea-7e5808e748be",
   "metadata": {},
   "source": [
    "To reorder columns, simply use select() with the wanted order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50f25381-cac5-4c1b-9a3d-65330ddfb8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- AudienceTargetAgeID: integer (nullable = true)\n",
      " |-- AudienceTargetEthnicID: integer (nullable = true)\n",
      " |-- BroadcastOriginPointID: integer (nullable = true)\n",
      " |-- CategoryID: integer (nullable = true)\n",
      " |-- ClosedCaptionID: integer (nullable = true)\n",
      " |-- CompositionID: integer (nullable = true)\n",
      " |-- CountryOfOriginID: integer (nullable = true)\n",
      " |-- DubDramaCreditID: integer (nullable = true)\n",
      " |-- Duration: string (nullable = true)\n",
      " |-- EndTime: string (nullable = true)\n",
      " |-- EthnicProgramID: integer (nullable = true)\n",
      " |-- ExhibitionID: integer (nullable = true)\n",
      " |-- FilmClassificationID: integer (nullable = true)\n",
      " |-- Language1: integer (nullable = true)\n",
      " |-- Language2: integer (nullable = true)\n",
      " |-- LogDate: date (nullable = true)\n",
      " |-- LogEntryDate: date (nullable = true)\n",
      " |-- LogServiceID: integer (nullable = true)\n",
      " |-- NetworkAffiliationID: integer (nullable = true)\n",
      " |-- Producer1: string (nullable = true)\n",
      " |-- Producer2: string (nullable = true)\n",
      " |-- ProductionNO: string (nullable = true)\n",
      " |-- ProductionSourceID: integer (nullable = true)\n",
      " |-- ProgramClassID: integer (nullable = true)\n",
      " |-- ProgramTitle: string (nullable = true)\n",
      " |-- SpecialAttentionID: integer (nullable = true)\n",
      " |-- StartTime: string (nullable = true)\n",
      " |-- Subtitle: string (nullable = true)\n",
      " |-- duration_seconds: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs.select(sorted(logs.columns)).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b9e9d6-253a-4fee-af3a-4e0311b89e28",
   "metadata": {},
   "source": [
    "#### <b>Diagnosing a data frame with describe() and summary()</b>\n",
    "\n",
    "quickly exploring numerical columns\n",
    " * describe(): summary statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa98eb55-e40c-4e0d-a7b5-e3cd5e124ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      LogServiceID|\n",
      "+-------+------------------+\n",
      "|  count|            238945|\n",
      "|   mean| 3450.890284375065|\n",
      "| stddev|199.50673962555592|\n",
      "|    min|              3157|\n",
      "|    max|              3925|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+\n",
      "|summary|\n",
      "+-------+\n",
      "|  count|\n",
      "|   mean|\n",
      "| stddev|\n",
      "|    min|\n",
      "|    max|\n",
      "+-------+\n",
      "\n",
      "+-------+-------------------+\n",
      "|summary|AudienceTargetAgeID|\n",
      "+-------+-------------------+\n",
      "|  count|              16112|\n",
      "|   mean| 3.4929245283018866|\n",
      "| stddev| 1.0415963394745125|\n",
      "|    min|                  1|\n",
      "|    max|                  4|\n",
      "+-------+-------------------+\n",
      "\n",
      "+-------+----------------------+\n",
      "|summary|AudienceTargetEthnicID|\n",
      "+-------+----------------------+\n",
      "|  count|                  1710|\n",
      "|   mean|    120.56432748538012|\n",
      "| stddev|     71.98694059436133|\n",
      "|    min|                     4|\n",
      "|    max|                   337|\n",
      "+-------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in logs.columns[:4]:\n",
    "    logs.describe(i).show()\n",
    "\n",
    "## if not compatible, PySpark only displays the title column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48560722-90ab-4f5c-b055-7af52ceca15b",
   "metadata": {},
   "source": [
    "Where descibre() takes *cols as an parameter, summary() takes *statistics as parameter. So you have to select the columns you want to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bd5ce4f8-bbb5-4e38-90d5-262081e11a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      LogServiceID|\n",
      "+-------+------------------+\n",
      "|  count|            238945|\n",
      "|   mean| 3450.890284375065|\n",
      "| stddev|199.50673962555592|\n",
      "|    min|              3157|\n",
      "|    25%|              3287|\n",
      "|    50%|              3379|\n",
      "|    75%|              3627|\n",
      "|    max|              3925|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+\n",
      "|summary|\n",
      "+-------+\n",
      "|  count|\n",
      "|   mean|\n",
      "| stddev|\n",
      "|    min|\n",
      "|    25%|\n",
      "|    50%|\n",
      "|    75%|\n",
      "|    max|\n",
      "+-------+\n",
      "\n",
      "+-------+-------------------+\n",
      "|summary|AudienceTargetAgeID|\n",
      "+-------+-------------------+\n",
      "|  count|              16112|\n",
      "|   mean| 3.4929245283018866|\n",
      "| stddev| 1.0415963394745125|\n",
      "|    min|                  1|\n",
      "|    25%|                  4|\n",
      "|    50%|                  4|\n",
      "|    75%|                  4|\n",
      "|    max|                  4|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in logs.columns[:3]:\n",
    "    logs.select(i).summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "60a998d7-cfcb-4f13-a7be-a9ac0cf8d5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+\n",
      "|summary|LogServiceID|\n",
      "+-------+------------+\n",
      "|    min|        3157|\n",
      "|    max|        3925|\n",
      "+-------+------------+\n",
      "\n",
      "+-------+\n",
      "|summary|\n",
      "+-------+\n",
      "|    min|\n",
      "|    max|\n",
      "+-------+\n",
      "\n",
      "+-------+-------------------+\n",
      "|summary|AudienceTargetAgeID|\n",
      "+-------+-------------------+\n",
      "|    min|                  1|\n",
      "|    max|                  4|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in logs.columns[:3]:\n",
    "    logs.select(i).summary('min','max').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cc86b0-c0af-4fec-8ab8-1a3b1428c1af",
   "metadata": {},
   "source": [
    "We can input count, mean, stddev, min, or max\n",
    "\n",
    "* Note: both methods work <b>ONLY</b> on non-null values. Null values will not be counted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9625c5a9-0c90-4f86-8521-57d72cdf1a59",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9ef50f-5ebd-4702-9304-eb15f4282528",
   "metadata": {},
   "source": [
    "Reread the data in a logs_raw data frame (the data file is ./data/broadcast_logs-\n",
    "BroadcastLogs_2018_Q3_M8.CSV), this time without passing any optional parameters.\n",
    "Print the first five rows of data, as well as the schema. What are the differences in\n",
    "terms of data and schema between logs and logs_raw?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c5a68e57-c31d-4745-8d73-52bd9b3e4f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = spark.read.csv(\n",
    "    broadcast_sample,\n",
    "    sep=\"|\",\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    "    timestampFormat=\"yyyy-MM-dd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4adbf91e-28ef-478e-958c-b78582077fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_raw = spark.read.csv(\n",
    "    broadcast_sample\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "640168e8-b35e-4be2-a7a6-5c924243b6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 _c0|\n",
      "+--------------------+\n",
      "|BroadcastLogID|Lo...|\n",
      "|1196192316|3157|2...|\n",
      "|1196192317|3157|2...|\n",
      "|1196192318|3157|2...|\n",
      "|1196192319|3157|2...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs_raw.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "172c8c6e-ba68-47e0-888a-b28d552f2a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs_raw.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ccde2b-fb16-40f6-83e2-aa85eb2f029f",
   "metadata": {},
   "source": [
    "As we see, all gets read as a single string column, with column name _c0, as default convention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ad8bdf-cfd2-47dc-9dda-a0cae19b14f4",
   "metadata": {},
   "source": [
    "Create a new data frame, logs_clean, that contains only the columns that do not\n",
    "end with ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fd39e70d-322e-4d06-957f-d88c4cfeca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_clean = logs.select(*[i for i in logs.columns if not i.endswith(\"ID\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "99af867d-a8f9-4398-9f13-711144f2d864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LogDate: date (nullable = true)\n",
      " |-- SequenceNO: integer (nullable = true)\n",
      " |-- Duration: string (nullable = true)\n",
      " |-- EndTime: string (nullable = true)\n",
      " |-- LogEntryDate: date (nullable = true)\n",
      " |-- ProductionNO: string (nullable = true)\n",
      " |-- ProgramTitle: string (nullable = true)\n",
      " |-- StartTime: string (nullable = true)\n",
      " |-- Subtitle: string (nullable = true)\n",
      " |-- Producer1: string (nullable = true)\n",
      " |-- Producer2: string (nullable = true)\n",
      " |-- Language1: integer (nullable = true)\n",
      " |-- Language2: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs_clean.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a698e61e-5064-4e81-a692-4923356eb720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
